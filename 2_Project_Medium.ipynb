{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Histology Tissue Classification Project (HTCP)"],"metadata":{"id":"RQxvD55PwFJf"}},{"cell_type":"markdown","source":["\n","\n","(C) [K. Mader](https://www.linkedin.com/in/kevinmader/?originalSubdomain=ch) / [U. Michelucci 2018-2019](https://www.linkedin.com/in/umbertomichelucci/?originalSubdomain=ch)\n","\n","*Teaching Assistant:* [Khaled Mohamad](https://www.linkedin.com/in/khaled-mohamad-45071a24b/).\n","\n","# Overview\n","\n","The dataset serves as a much more interesting MNIST or CIFAR10 problem for biologists by focusing on histology tiles from patients with colorectal cancer. In particular, the data has 8 different classes of tissue (but Cancer/Not Cancer can also be an interesting problem).\n","\n","The dataset has been adapted for the course by K. Mader (kevin.mader@gmail.com), and is available on kaggle: https://goo.gl/26zj41\n","\n","# Challenge\n","\n","* Classify tiles correctly into one of the eight classes\n","* Which classes are most frequently confused?\n","* What features can be used (like texture, see scikit-image) to improve classification?\n","* How can these models be applied to the much larger 5000x5000 models? How can this be done efficiently\n","\n","# Acknowledgements\n","\n","\n","The dataset has been copied from Zenodo: https://zenodo.org/record/53169#.W6HwwP4zbOQ\n","\n","made by: Kather, Jakob Nikolas; Zöllner, Frank Gerrit; Bianconi, Francesco; Melchers, Susanne M; Schad, Lothar R; Gaiser, Timo; Marx, Alexander; Weis, Cleo-Aron\n","\n","The copy here is to make it more accessible to Kaggle users and allow kernels providing basic analysis of the data\n","\n","Content This data set represents a collection of textures in histological images of human colorectal cancer. It contains two files:\n","\n",">     Kather_texture_2016_image_tiles_5000.zip\": a zipped folder containing 5000 \n",">     histological images of 150 * 150 px each (74 * 74 µm). Each image belongs \n",">     to exactly one of eight tissue categories (specified by the folder name). \n","\n",">     Kather_texture_2016_larger_images_10.zip\": a zipped folder containing 10 \n",">     larger histological images of 5000 x 5000 px each. These images contain \n",">     more than one tissue type. Image format\n","\n","\n","All images are RGB, 0.495 µm per pixel, digitized with an Aperio ScanScope \n","(Aperio/Leica biosystems), magnification 20x. Histological samples are fully \n","anonymized images of formalin-fixed paraffin-embedded human colorectal \n","adenocarcinomas (primary tumors) from our pathology archive (Institute of Pathology, \n","University Medical Center Mannheim, Heidelberg University, Mannheim, Germany).\n","\n","Additionally the files has been prepared to resemble the MNIST dataset, meaning that you will also find the following files\n","\n","- HTCP_8_8_L - \n","- HTCP_8_8_RGB -\n","- HTCP_28_28_L -\n","- HTCP_28_28_RGB - \n","- HTCP_64_64_L\n","\n","# Ethics statement\n","All experiments were approved by the institutional ethics board (medical ethics board II, University Medical Center Mannheim, Heidelberg University, Germany; approval 2015-868R-MA). The institutional ethics board waived the need for informed consent for this retrospective analysis of anonymized samples. All experiments were carried out in accordance with the approved guidelines and with the Declaration of Helsinki.\n","\n","# More information / data usage\n","For more information, please refer to the following article. Please cite this article when using the data set.\n","\n","Kather JN, Weis CA, Bianconi F, Melchers SM, Schad LR, Gaiser T, Marx A, Zollner F: Multi-class texture analysis in colorectal cancer histology (2016), Scientific Reports (in press)\n","\n","# Contact\n","For questions, please contact: Dr. Jakob Nikolas Kather http://orcid.org/0000-0002-3730-5348 ResearcherID: D-4279-2015\n"],"metadata":{"id":"NStyZnPF2dwO"}},{"cell_type":"markdown","source":["# Download the data"],"metadata":{"id":"uBrmZ0hC298g"}},{"cell_type":"markdown","source":["The dataset is composed of two datasets:\n","\n","- The small images that will be used to test the classification models\n","- The big microscope images (5000x5000)\n","\n","The first dataset is quite small and can be found in the same github repository where you find this file. The second are much bigger (250 Mb and 700 Mb) and cannot be uploaded on github, so you can get them on kaggle: https://goo.gl/hkRSke"],"metadata":{"id":"-ug-JIdU3HYa"}},{"cell_type":"markdown","source":["# Ideas for the project\n","\n","The project can be tackled in several ways and at several levels. Here are some ideas for you to tackle at different difficulty levels.\n","\n","A few general hints:\n","\n","- Accuracy is a nice metric, but in this case the confusion matrix is more useful. Check which metric is the most ideal for this problem (you could use others)\n","- If detecting TUMOR proces too hard, try to detect other tissue types. For example ADIPOSE. Some are much easier to detect than others. \n","- __REMEMBER__: detecting __ONE__ type of tissue does not necessarly mean being able to detec __ALL__ type of tissues well ;-)\n","- __REMEMBER__: getting a high accuracy is __NOT__ the goal of the project. The goal is to put you in a real-life situation where you have to be creative to solve a relevant problem. Is not easy and there are not easy ways of solving it.\n","\n","__OVER ALL REMEMBER: HAVE FUN!__\n","\n","\n","## Medium\n","- Use the gray level 28x28 images and consider all the classes. Try to build a classifier using a neural network with several layers. After a first test, with hyperparameter tuning try to find the best model for the problem. Consider the following hyperparameters\n","    - learning rate\n","    - number of layers / Number of neurons in each layer\n","    - mini-batch size\n","    - number of epochs\n","    - activation function (maybe swish helps?)\n","- After having tried what just described in the previous point, try to see if you get better results with the 64x64 gray images. And try with the 8x8 to see if they are usable to get better results (they are not, but try).\n","\n","\n","\n"],"metadata":{"id":"UvhhfhKN3qh8"}},{"cell_type":"markdown","source":["\n","##__STARTING WITH__:\n","## 2. Medium!"],"metadata":{"id":"GsUGv_iA7ZRP"}},{"cell_type":"markdown","source":["# Helper Functions (Python)"],"metadata":{"id":"DmA9x2MC5rad"}},{"cell_type":"code","source":["# A function for plotting images\n","\n","def plot_image(some_image):\n","    \n","    some_digit_image = some_image.values.reshape(28,28)\n","\n","    plt.imshow(some_digit_image, cmap = matplotlib.cm.binary, interpolation = \"nearest\")\n","    plt.axis(\"off\")\n","    plt.show()\n","    "],"metadata":{"id":"zy6OyIyl419w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# A function to get Label names(are eight)\n","\n","def get_label_name(idx):\n","    \n","    if (idx == 1):\n","        return '(1) TUMOR'\n","    elif (idx == 2):\n","        return '(2) STROMA'\n","    elif (idx == 3):\n","        return '(3) COMPLEX'\n","    elif (idx == 4):\n","        return '(4) LYMPHO'\n","    elif (idx == 5):\n","        return '(5) DEBRIS'\n","    elif (idx == 6):\n","        return '(6) MUCOSA'\n","    elif (idx == 7):\n","        return '(7) ADIPOSE'\n","    elif (idx == 8):\n","        return '(8) EMPTY'"],"metadata":{"id":"2rJr2R3J_Bnj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load & Importing Libraries"],"metadata":{"id":"Xm5mqcLFCbY-"}},{"cell_type":"code","source":["# Load python libraries\n","\n","%matplotlib inline\n","from glob import glob\n","import os\n","import matplotlib.pyplot as plt\n","import matplotlib\n","import numpy as np\n","import pandas as pd\n","from random import randint\n","\n","# Read images from files and plot\n","from skimage.io import imread \n","import seaborn as sns\n","\n","# Tensorflow & Keras is imported for building and training models\n","import tensorflow as tf\n","\n","# Keras \n","from tensorflow.keras.models import Sequential # for building the  layers\n","from tensorflow.keras.optimizers import SGD    # Optimizer \n","from tensorflow.keras.layers import Dense      # Connected network\n","\n","from tensorflow.keras import layers\n","import tensorflow.keras as keras\n","from sklearn.metrics import confusion_matrix, accuracy_score   # Measure performance of your classifier and accuracy\n","import time"],"metadata":{"id":"6JiMvE9HCMP8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Checking your TensorFlow Version\n","##### __Uncomment__ the cell below and run it"],"metadata":{"id":"YyhqRLixVZx_"}},{"cell_type":"code","source":["\n","# ver_1= '2.10.0'\n","\n","# def tf_version(tf):\n","#   tf_v = tf.__version__\n","#   if tf_v >= ver_1:\n","#     print(f\" Your veriosn of TensorFlow is a:{tf_v}  satisfied!\")\n","#   else:\n","#     print(\"Your new version of TensroFlow updating ....\")\n","#     !pip3 install --upgrade tensorflow\n","\n","# tf_version(tf)\n"],"metadata":{"id":"rQFFbc7RvmUe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load the Data\n","#### __Replace__ your current directory path with '/content/data\n","#### __Uncomment__ the last two lines of code below USING ( Ctrl + / ) and run your cell"],"metadata":{"id":"NbnSJU80HNSS"}},{"cell_type":"code","source":["# Know Image Dimensions\n","def know_image_dim(in_shape):\n","\n","    side_len = int(np.sqrt(in_shape))\n","    abs_value = np.abs(in_shape-side_len*side_len)<2\n","    negative_value = side_len = int(np.sqrt(in_shape/3))\n","\n","    if abs_value:\n","        return (int(side_len), int(side_len))\n","    else:\n","        negative_value\n","        return (side_len, side_len, 3)\n","        \n","# csv_dir = os.path.join('.', '/content/data')\n","# print(f\"My current working directory is: {csv_dir} \")"],"metadata":{"id":"lOo-90S0kWOg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Print your Vector size for evey dataset\n","#### __Uncomment__ code below and run your cell"],"metadata":{"id":"zemVDRLck-3l"}},{"cell_type":"code","source":["# Return all file names from current directory and sort in ascending orders(shaps)\n","all_files = sorted(glob(os.path.join(csv_dir, 'HTCP*.csv')), \n","                   key=lambda x: os.stat(x).st_size)\n","\n","\n","\n","# all_df_dict = {os.path.splitext(os.path.basename(x))[0]: pd.read_csv(x) for x in all_files}\n","# print(\"VECTOR SIZE FOR EVERY DATASET:\\n\")\n","# for c_key in all_df_dict.keys():\n","#     print(c_key, 'vector length:',  \n","#           all_df_dict[c_key].shape[1], '->', \n","#             know_image_dim(all_df_dict[c_key].shape[1]))"],"metadata":{"id":"7ohRbx0hlgr3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Print the folder and data paths\n","#### __Uncomment__ all_files and run"],"metadata":{"id":"RwpjUBqMl6ur"}},{"cell_type":"code","source":["# all_files"],"metadata":{"id":"pk5x6GapmL05"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Read csv file from list(all_files)\n","data = pd.read_csv(all_files[2])"],"metadata":{"id":"t5pMU4SYHe9R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's create an array with labels (not yet one-encoded) and one for the images."],"metadata":{"id":"xmGxOrgpIA_h"}},{"cell_type":"markdown","source":["# Get the labels from the data\n","#### __Uncomment__  code below and run your cell"],"metadata":{"id":"7pruG3LBod8f"}},{"cell_type":"code","source":["\n","# labels = data['label']\n","# data = data.drop(['label'], axis = 1)\n"],"metadata":{"id":"PoO_0hLaza48"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Baseline models with 28x28 gray images"],"metadata":{"id":"7givs_A1a34k"}},{"cell_type":"markdown","source":["\n","### Import python libraries\n","##### __Uncomment__ code below and run your cell\n"],"metadata":{"id":"rhnEwofSowmi"}},{"cell_type":"code","source":["# from sklearn.model_selection import train_test_split\n","# sample_id_count = list(all_df_dict.values())[0].shape[0]\n","# train_ids, test_ids = train_test_split(range(sample_id_count), \n","#                                        test_size=0.25, \n","#                                        random_state=2018)"],"metadata":{"id":"9olNbtq1a44l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, accuracy_score\n","\n","def evaluate_models(in_model_maker):\n","    fig, m_axs = plt.subplots(1, 5, figsize = (25, 5))\n","    for c_ax, c_key in zip(m_axs, all_df_dict.keys()):\n","        # c_key is for example HTCP_8_8_L (the file/type name)\n","        c_df = all_df_dict[c_key].copy()\n","        c_label = c_df.pop('label') # return column and drop from dataframe\n","        c_model = in_model_maker() # function of the model\n","        c_model.fit(c_df.iloc[train_ids, :], c_label.iloc[train_ids]) # fit of the model\n","        c_pred = c_model.predict(c_df.iloc[test_ids, :]) # prediction\n","        sns.heatmap(confusion_matrix(c_label.iloc[test_ids], c_pred), \n","                    annot=True, cbar=False, fmt='d', ax=c_ax)\n","        c_ax.set_title(f'Accuracy: {accuracy_score(c_label[test_ids],c_pred)*100:2.2f}%\\n{c_key}')"],"metadata":{"id":"ll0wA1PLa7h2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Example of a network with 4 layers, each with 10 neurons"],"metadata":{"id":"VYZqpFCPZR5t"}},{"cell_type":"code","source":["class NBatchLogger(keras.callbacks.Callback):\n","    \"\"\"\n","    A Logger that log average performance per `display` steps.\n","    \"\"\"\n","    def __init__(self, display):\n","        self.step = 0\n","        self.display = display\n","        self.metric_cache = {}\n","\n","    def on_batch_end(self, batch, logs=None):\n","        self.step += 1\n","        for k in self.model.metrics:\n","            if k.name not in self.metric_cache.keys():\n","                self.metric_cache[k.name] = 0.0\n","            self.metric_cache[k.name] += logs.get(k.name)\n","        if self.step % self.display == 0:\n","            metrics_log = ''\n","            for (k, v) in self.metric_cache.items():\n","                val = v / self.display\n","                if abs(val) > 1e-3:\n","                    metrics_log += ' - %s: %.4f' % (k, val)\n","                else:\n","                    metrics_log += ' - %s: %.4e' % (k, val)\n","            print('step: {}/{} ... {}'.format(self.step,\n","                                          self.params['steps'],\n","                                          metrics_log))\n","            self.metric_cache.clear()"],"metadata":{"id":"YHXXq9NnZQVE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Make a copy of Data and Labels.\n","#### __Uncomment__ code below and run your cell"],"metadata":{"id":"HBfVaBecpLc6"}},{"cell_type":"code","source":["\n","# c_df = all_df_dict['HTCP_28_28_L'].copy()\n","# c_label = c_df.pop('label')\n"],"metadata":{"id":"TwU0ePL4akh3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Split your data inot train and test set\n","#### __Uncomment__ code below and run your cell"],"metadata":{"id":"vgS8Akx9puRA"}},{"cell_type":"code","source":["\n","# X_train = c_df.iloc[train_ids, :]\n","# y_train = c_label.iloc[train_ids]-1"],"metadata":{"id":"Tj3v0O-5a6bU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# X_test = c_df.iloc[test_ids, :]\n","# ytest = c_label.iloc[test_ids]-1"],"metadata":{"id":"wl6O0aiLbIkV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Print shape of your dataset\n","#### __Uncomment__ code below and run your cell"],"metadata":{"id":"k27T1qLzp9Hc"}},{"cell_type":"code","source":["# X_train.shape"],"metadata":{"id":"wCE-nN7MqFh_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# convert class vectors to binary class matrices One Hot Encoding\n","num_of_classes = 8\n","y_train = keras.utils.to_categorical(y_train, num_of_classes)\n","X_train, X_val, Y_train, Y_val = train_test_split(X_train, y_train, \n","                                                  test_size = 0.1, random_state=42)\n","\n","X_train = X_train / 255.0 / 1.0\n","X_val = X_val / 255.0 / 1.0"],"metadata":{"id":"5En0SCTDd2Ii"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Building Neural Network Phases\n","#### __Your task__ change activation function to relu:    (activation='relu')\n","######1. __Uncomment__ the 3 lines of the code below first!\n","######2. __Change__ your optimizers to Adam : optimizer=tf.optimizers.Adam(0.01)"],"metadata":{"id":"MHGW13DrqjpU"}},{"cell_type":"code","source":["n = 15\n","model = tf.keras.Sequential()\n","model.add(layers.Dense(n, input_dim=X_train.shape[1], activation='relu'))\n","# model.add(layers.Dense(n, activation='relu'))\n","model.add(layers.Dropout(0.40))\n","# model.add(layers.Dense(n, activation='relu'))\n","model.add(layers.Dropout(0.40))\n","# model.add(layers.Dense(n, activation='relu'))\n","model.add(layers.Dropout(0.40))\n","model.add(layers.Dense(num_of_classes, activation='softmax'))\n","\n","model.compile(loss=keras.losses.categorical_crossentropy,\n","              # optimizer=tf.optimizers,\n","              metrics=['accuracy'])\n","    \n"],"metadata":{"id":"QxI7TUmus3Xe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#  Run Model Summary\n"],"metadata":{"id":"CpjsXlmvskXM"}},{"cell_type":"code","source":["# model.summary()"],"metadata":{"id":"Br2hLA5WspeU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train dataset with 1000 iterations\n","##### __Uncomment__ the code below and run"],"metadata":{"id":"o6a_P4pDtJe_"}},{"cell_type":"code","source":["out_batch = NBatchLogger(display=1000)\n","model.fit(X_train, Y_train, epochs=1000, batch_size=250,verbose = 0,\n","             callbacks=[out_batch])\n"],"metadata":{"id":"eZoClA7MtcVK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","# Measure your final loss and accuracy model\n","##### __Uncomment__ the code below and run the cell"],"metadata":{"id":"v8TZD6Jftsou"}},{"cell_type":"code","source":["final_loss, final_acc = model.evaluate(X_val, Y_val, verbose=1)\n","pred = np.argmax(model.predict(X_val), axis=-1)\n","pred_train = np.argmax(model.predict(X_train), axis=-1)\n","print(\"Final loss: {0:.6f}, final accuracy: {1:.6f}\".format(final_loss, final_acc))"],"metadata":{"id":"09o7GFGlt6wk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Visualize your Confusion Matrix for trained dataset\n","##### __Uncomment__ the code below and run the cell"],"metadata":{"id":"5kQb5XgAuCO-"}},{"cell_type":"code","source":["# sfig = plt.figure(figsize=(7,7))\n","# ax = fig.add_subplot(1, 1, 1)\n","# sns.heatmap(confusion_matrix(np.argmax(Y_train, axis = 1), pred_train), \n","#                     annot=True, cbar=False, fmt='d', ax=ax)"],"metadata":{"id":"iuDq-7Q8unTj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Congratulation ! end of this exercise(2), We hope you enjoyed! \n","### __You have learned __\n","\n","1. Import the dataset\n","2. Find your working directory path\n","3. Split the data to training set (x) data, and test set labels(y)\n","4. Build Neural Network phases\n","5. Fit your model (training data)\n","6. Print loss and accurcy of your model\n","7. Visualize your Confusion Matrix\n","\n","\n"],"metadata":{"id":"sVakFQVYuu2d"}}]}